# Example Environment File for GR00T Fine-tuning Workflow
# Copy this file to .env and fill in your values

# ==========================================
# AUTHENTICATION (optional)
# ==========================================
# HF_TOKEN is only required if pulling dataset from HF or uploading model to HF
HF_TOKEN=<your_huggingface_token_here>

# ==========================================
# DATASET SOURCE SELECTION (all optional)
# The entrypoint resolves in this order: local -> s3 -> hf -> sample
# ==========================================
# DATASET_LOCAL_DIR: Use a local dataset path (e.g., mounted volume)
DATASET_LOCAL_DIR=/workspace/train
# DATASET_S3_URI: Sync dataset from S3 (e.g., s3://my-bucket/datasets/so100)
DATASET_S3_URI=
# HF_DATASET_ID: Download dataset from Hugging Face (e.g., lerobot/datasets)
HF_DATASET_ID=

# ==========================================
# UPLOAD CONFIGURATION (optional)
# UPLOAD_TARGET: hf | s3 | none
# ==========================================
# UPLOAD_TARGET: Set to 'hf' for Hugging Face, 's3' for S3, or 'none' to skip
UPLOAD_TARGET=none
# HF_MODEL_REPO_ID: Required if UPLOAD_TARGET=hf (e.g., your-username/your-model)
HF_MODEL_REPO_ID=
# S3_UPLOAD_URI: Required if UPLOAD_TARGET=s3 (e.g., s3://my-bucket/models/)
S3_UPLOAD_URI=

# ==========================================
# OUTPUT DIRECTORIES (optional)
# By default, the script writes to /mnt/efs/gr00t/checkpoints if mounted
# ==========================================
# OUTPUT_DIR: Override default checkpoint directory
OUTPUT_DIR=

# ==========================================
# BASIC TRAINING PARAMETERS
# ==========================================
MAX_STEPS=6000
SAVE_STEPS=2000
NUM_GPUS=1
BATCH_SIZE=32
LEARNING_RATE=1e-4
WEIGHT_DECAY=1e-5
WARMUP_RATIO=0.05

# ==========================================
# MODEL AND DATA CONFIGURATION
# ==========================================
BASE_MODEL_PATH=nvidia/GR00T-N1.5-3B@3c235401cb51575b3f091e68de96dc0785de971d
DATA_CONFIG=so100_dualcam
VIDEO_BACKEND=torchvision_av
EMBODIMENT_TAG=new_embodiment

# Valid DATA_CONFIG options:
# - so100_dualcam
# - fourier_gr1_arms_only
# - fourier_gr1_arms_waist
# - agibot_genie1_dualcam
# - oxe_droid_single_cam

# Valid EMBODIMENT_TAG options:
# - new_embodiment
# - gr1
# - oxe_droid
# - agibot_genie1

# ==========================================
# FINE-TUNING CONFIGURATION
# ==========================================
TUNE_LLM=false
TUNE_VISUAL=false
TUNE_PROJECTOR=true
TUNE_DIFFUSION_MODEL=true

# ==========================================
# LORA CONFIGURATION
# ==========================================
LORA_RANK=0
LORA_ALPHA=16
LORA_DROPOUT=0.1
LORA_FULL_MODEL=false

# ==========================================
# DATASET BALANCING
# ==========================================
BALANCE_DATASET_WEIGHTS=true
BALANCE_TRAJECTORY_WEIGHTS=true

# ==========================================
# PERFORMANCE AND SYSTEM
# ==========================================
DATALOADER_NUM_WORKERS=8

# ==========================================
# WORKFLOW CONTROL
# ==========================================
RESUME=false
CLEANUP_DATASET=false
CLEANUP_CHECKPOINTS=false

# ==========================================
# LOGGING AND MONITORING
# ==========================================
REPORT_TO=tensorboard

# Weights & Biases Configuration (set REPORT_TO=wandb to use)
WANDB_API_KEY=your_wandb_api_key
WANDB_PROJECT=gr00t-finetune
WANDB_ENTITY=your_wandb_entity

# ==========================================
# CONFIGURATION EXAMPLES
# ==========================================

# Example 1: Use Local Dataset and Upload to S3
# DATASET_LOCAL_DIR=/workspace/train
# UPLOAD_TARGET=s3
# S3_UPLOAD_URI=s3://my-bucket/models/gr00t-finetuned/

# Example 2: Download from HF and Upload to HF
# HF_DATASET_ID=lerobot/datasets
# UPLOAD_TARGET=hf
# HF_MODEL_REPO_ID=your-username/gr00t-so100-finetuned
# HF_TOKEN=your_actual_hf_token

# Example 3: Use Sample Dataset (Default) and Skip Upload
# UPLOAD_TARGET=none
# (No dataset or upload variables needed)

# Example 4: Use S3 Dataset and Upload to S3
# DATASET_S3_URI=s3://my-bucket/datasets/so100
# UPLOAD_TARGET=s3
# S3_UPLOAD_URI=s3://my-bucket/models/gr00t-finetuned/

# Example 5: LoRA Fine-tuning
# LORA_RANK=32
# LORA_ALPHA=64
# TUNE_PROJECTOR=false
# TUNE_DIFFUSION_MODEL=false
# TUNE_LLM=false
# TUNE_VISUAL=false

# Example 6: Full Fine-tuning
# TUNE_LLM=true
# TUNE_VISUAL=true
# TUNE_PROJECTOR=true
# TUNE_DIFFUSION_MODEL=true
# LORA_RANK=0

# Example 7: Projector + Diffusion Only (Recommended)
# TUNE_LLM=false
# TUNE_VISUAL=false
# TUNE_PROJECTOR=true
# TUNE_DIFFUSION_MODEL=true
# LORA_RANK=0

# Example 8: Resume Training from Checkpoint
# RESUME=true
# OUTPUT_DIR=/workspace/checkpoints  # Should contain previous checkpoints

# Example 9: WandB Logging
# REPORT_TO=wandb
# WANDB_API_KEY=your_actual_wandb_api_key
# WANDB_PROJECT=my-gr00t-project
# WANDB_ENTITY=my-wandb-username 